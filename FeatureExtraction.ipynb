pip install tensorflow

pip install opencv-python-headless

import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import GlobalMaxPooling2D, Input
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import Model


print("TensorFlow version:", tf.__version__)
print("Keras version:", tf.keras.__version__)

# Define the model with the input shape
model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
model.trainable = False

#model.summary()


# Define the input layer
inputs = Input(shape=(224, 224, 3))

# Pass the inputs through the base model
x = model(inputs, training=False)

# Add a MaxPooling2D layer
x = GlobalMaxPooling2D()(x)

# Define the model
model = Model(inputs, x)



import cv2
import os
import matplotlib.pyplot as plt

# Print the current working directory
print("Current Working Directory:", os.getcwd())

# Update the image path according to your current working directory
img_path = "C:/Users/MANASWINI KARNATAKA/Desktop/data/Footwear/Women/Images/images_with_product_ids/11496.jpg"
print("Image Path:", img_path)

# Load the image
img = cv2.imread(img_path)

if img is None:
    print("Error: Image not found or unable to load.")
else:
    # Convert the image to RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Display the image using matplotlib
    plt.imshow(img_rgb)
    plt.axis('off')  # Hide axes
    plt.show()



import cv2
import numpy as np
from numpy.linalg import norm

#resizing the img
img_path = "C:/Users/MANASWINI KARNATAKA/Desktop/data/Footwear/Women/Images/images_with_product_ids/11496.jpg"
img = cv2.imread(img_path)

print("Before :",img.shape)
img=cv2.resize(img,(224,224))
#img=np.array(img)
print("After :",img.shape)


#(no_of_img,224,224,3)
expand_img=np.expand_dims(img,axis=0)
expand_img.shape

pre_img=preprocess_input(expand_img)
pre_img.shape

pre_img

result = model.predict(pre_img).flatten()
print("shape:",result.shape)
print(result)


#normalization
normalized=result/norm(result)
print("shape:",normalized.shape)
print("normalized result:",normalized)


#preprocessing 
def extract_feature(img_path, model):
    try:
        img=cv2.imread(img_path)
        # Check if the image is loaded
        if img is None:
            print(f"Error: Unable to load image at {img_path}")
            return None
            
        img=cv2.resize(img,(224,224))
        img=np.array(img)
        expand_img=np.expand_dims(img,axis=0)
        pre_img=preprocess_input(expand_img)
        # Extract features using the model
        result=model.predict(pre_img).flatten()
        normalized=result/norm(result)
        normalized = np.squeeze(normalized)
        return normalized
    except Exception as e:
        print(f"Exception occurred for image {img_path}: {e}")
        return None



extract_feature('C:/Users/MANASWINI KARNATAKA/Desktop/data/Footwear/Women/Images/images_with_product_ids/11496.jpg',model)


import os
from tqdm import tqdm

filename = []



# Append paths from each directory
directories = [
    'C:/Users/MANASWINI KARNATAKA/Desktop/data/Apparel/Boys/Images/images_with_product_ids',
    'C:/Users/MANASWINI KARNATAKA/Desktop/data/Apparel/Girls/Images/images_with_product_ids',
    'C:/Users/MANASWINI KARNATAKA/Desktop/data/Footwear/Men/Images/images_with_product_ids',
    'C:/Users/MANASWINI KARNATAKA/Desktop/data/Footwear/Women/Images/images_with_product_ids'
]

for directory in directories:
    for file in os.listdir(directory):
        filename.append(os.path.join(directory, file))


import sys
# Check the memory usage of the filename list
memory_usage = sys.getsizeof(filename) / (1024 ** 2)  # Convert bytes to megabytes
print(f"Memory usage of filename list: {memory_usage:.2f} MB")

filename[0:5]
#len(filename)


# Initialize feature_list
feature_list = []

# Process each file
for file in tqdm(filename):
    feature = extract_feature(file, model)
    if feature is not None:
        feature_list.append(feature)


import pickle
pickle.dump(feature_list,open('featurevector.pkl','wb'))
pickle.dump(filename,open('filenames.pkl','wb'))
